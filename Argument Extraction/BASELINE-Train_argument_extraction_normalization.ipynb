{"cells":[{"cell_type":"markdown","metadata":{"id":"aHFEf8hG4RUB"},"source":["# Triple and Perspective Extraction and Scoring with Normalization\n","\n","In this notebook you will be fine-tuning a language model to perform triple argument (Subject, Predicate, Object) extraction and candidate triple scoring. For the predicates, you will create various categories, and the aim of the model is to find the predicate token span as well as the most likely category for the predicate. You will use the `pytorch` implementation of `albert-base` provided by the Huggingface `transformers` library and fine-tune this model on PersonaChat, DailyDialog and Circa data annotated with ground-truth triples. You will also try adapt the code to allow for other models and train those models to compare model performances on the normalized predicates. \n","\n","## Overview \n","Adopting a two-stage setup allows maximum flexibility of the triple extraction while making efficient use of the annotated data. The two stages include:\n","\n","1. A sequence labeling (BIO-tagging) model which extracts lists of subjects, predicates and objects from the input dialogue.\n","\n","2. A model which takes combinations of subjects, predicates and objects found and scores these combinations (i.e. all candidate triples) to decide whether the triple can indeed be entailed from the dialogue and what its polarity is.\n","\n","By using this two-stage approach, arbitrary numbers of triples can be extracted and linguistic phenomena such as ellipsis can be accounted for.<br>\n","\n","The first part is most relevant for the extraction of abstract predicates, whereas the second part is relevant for the evaluation."]},{"cell_type":"markdown","metadata":{"id":"u6XnlD6P5Tl2"},"source":["## Getting the Data\n","\n","To get a dataset of ground truth triples a small development set was created. This data has been stored in Google Drive for easy access."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25396,"status":"ok","timestamp":1671015006279,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"n9SAUVRc4Jtc","outputId":"b2cc3a81-3c26-45b0-dad5-83d3213e5057"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","root_dir = '/content/gdrive/MyDrive/Communicative Robotics' \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20173,"status":"ok","timestamp":1671015033553,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"elKejMJz6tfG","outputId":"d7b66599-27de-4b05-e863-5453892be784"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': [['that',\n","   \"'s\",\n","   'nice',\n","   'i',\n","   'wish',\n","   'i',\n","   'was',\n","   'more',\n","   'creative'],\n","  ['what', 'kind', 'of', 'music', 'do', 'you', 'sing', '?'],\n","  ['pop',\n","   'music',\n","   'but',\n","   'i',\n","   'get',\n","   'nervous',\n","   'and',\n","   'do',\n","   \"n't\",\n","   'preform']],\n"," 'annotations': [[[[0, 3]],\n","   [[0, 4]],\n","   [[0, 5], [0, 6], [0, 7], [0, 8]],\n","   [],\n","   []],\n","  [[[1, 5]], [[1, 6]], [[2, 0], [2, 1]], [], []],\n","  [[[2, 3]], [[2, 4]], [[2, 5]], [], []],\n","  [[[2, 3]], [[2, 7]], [[2, 9]], [[2, 8]], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []]],\n"," 'skipped': False}"]},"metadata":{},"execution_count":2}],"source":["import glob\n","import json\n","import random\n","\n","def load_annotations(path, remove_unk=True, keep_skipped=False):\n","    \"\"\" Reads all annotation files from path. By default, it filters skipped\n","        files and removes the [unk] tokens appended at the end of each turn.\n","\n","        params:\n","        str path:           name of directory containing annotations\n","        bool remove_unk:    whether to remove [unk] tokens (default: True)\n","        bool keep_skipped:  whether to keep skipped annotations (default: False)\n","\n","        returns:    list of annotations dicts\n","    \"\"\"\n","    annotations = []\n","    for fname in glob.glob(path + '/*.json'):\n","        with open(fname, 'r', encoding='utf-8') as file:\n","            data = json.load(file)\n","\n","            if data['skipped'] and not keep_skipped:\n","                continue\n","\n","            if remove_unk:\n","                data['tokens'] = [[t for t in turn if t != '[unk]'] for turn in data['tokens']]\n","\n","            annotations.append(data)\n","\n","    return annotations\n","\n","annotations = load_annotations(root_dir + '/annotated_data/trainval') #include in new dir\n","annotations[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":336,"status":"ok","timestamp":1671015112072,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"qXwUWdkOEcmo","outputId":"38a2b7d4-737e-4502-ed49-1363d0fbe4e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["#dialogs: 1117\n","#triples: 4786\n"]}],"source":["print('#dialogs:', len(annotations))\n","print('#triples:', sum([sum([any(t) for t in d['annotations']]) for d in annotations]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mikx1fcmENVY"},"outputs":[],"source":["def get_predicate_tokens(annotation, triple):\n","\n","      if triple[1]:\n","        turn = triple[1][0][0]\n","        pred_tokens = []\n","        for n in range(0, len(triple[1])):\n","          token_index = triple[1][n][1]\n","          token = annotation['tokens'][turn][token_index]\n","          pred_tokens.append(token)\n","        return ' '.join(pred_tokens)\n","      else:\n","        return None\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CvSlrU9dH2xp"},"source":["## Who are 'You'?: Disambiguating You and I\n","\n","In the text the speakers are referred to as ambiguous tokens *You* and *I*. As these words are ambiguous and their meaning depends on the speaker who utters them, we replace these tokens by [SPEAKER1] and [SPEAKER2] contingent on the speaker (e.g. speaker 2 saying you indicates, [speaker1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlETfhBLIDeE"},"outputs":[],"source":["SPEAKER1 = 'SPEAKER1'\n","SPEAKER2 = 'SPEAKER2'\n","\n","def disambiguate_pronouns(token, turn_idx):\n","    # Even turns -> speaker1\n","    if turn_idx % 2 == 0:\n","        if token in ['i', 'me', 'myself', 'we', 'ourselves']:\n","            return SPEAKER1\n","        elif token in ['my', 'mine', 'our', 'ours']:\n","            return SPEAKER1 + \"'s\"\n","        elif token in ['you', 'yourself', 'yourselves']:\n","            return SPEAKER2\n","        elif token in ['your', 'yours']:\n","            return SPEAKER2 + \"'s\"\n","    else:\n","        if token in ['i', 'me', 'myself', 'we', 'ourselves']:\n","            return SPEAKER2\n","        elif token in ['my', 'mine', 'our', 'ours']:\n","            return SPEAKER2 + \"'s\"\n","        elif token in ['you', 'yourself', 'yourselves']:\n","            return SPEAKER1\n","        elif token in ['your', 'yours']:\n","            return SPEAKER1 + \"'s\"\n","    return token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1671015126320,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"Y0XasWY9IGNm","outputId":"ce6a5928-864d-4e02-ff01-a70c3b8536f9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': [['that',\n","   \"'s\",\n","   'nice',\n","   'SPEAKER1',\n","   'wish',\n","   'SPEAKER1',\n","   'was',\n","   'more',\n","   'creative'],\n","  ['what', 'kind', 'of', 'music', 'do', 'SPEAKER1', 'sing', '?'],\n","  ['pop',\n","   'music',\n","   'but',\n","   'SPEAKER1',\n","   'get',\n","   'nervous',\n","   'and',\n","   'do',\n","   \"n't\",\n","   'preform']],\n"," 'annotations': [[[[0, 3]],\n","   [[0, 4]],\n","   [[0, 5], [0, 6], [0, 7], [0, 8]],\n","   [],\n","   []],\n","  [[[1, 5]], [[1, 6]], [[2, 0], [2, 1]], [], []],\n","  [[[2, 3]], [[2, 4]], [[2, 5]], [], []],\n","  [[[2, 3]], [[2, 7]], [[2, 9]], [[2, 8]], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []],\n","  [[], [], [], [], []]],\n"," 'skipped': False}"]},"metadata":{},"execution_count":6}],"source":["for annotation in annotations:\n","    annotation['tokens'] = [[disambiguate_pronouns(token, i % 2) for token in turn] for i, turn in enumerate(annotation['tokens'])]\n","annotations[0]"]},{"cell_type":"markdown","metadata":{"id":"MMyhZF4e71Yl"},"source":["## Converting formats\n","\n","Triple arguments are stored as lists of indices (e.g. [[0, 1], [0, 2]] indicating the second and third token of the first turn). We rather use a BIO tagging scheme to indicate these arguments as a vector of labels (one label for each token in the dialog).\n","\n","Moreover, we flatten the dialogue turns into one flat dialogue using `<eos>` as a separator token."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFJv2Avc70hz"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import re\n","\n","\n","def triple_to_bio_tags(annotation, arg):\n","    \"\"\" Converts the token indices of the annotations to a vector of BIO labels\n","        for an argument.\n","\n","        params:\n","        dict annotation:    loaded annotation file (see load_annotations)\n","        int arg:            argument to create tag sequence for (subj=0, pred=1, obj=2)\n","\n","        returns:    ndarray with BIO labels (I=2, B=1, O=0)\n","    \"\"\" \n","    # Determine length of dialogue\n","    turns = annotation['tokens']\n","    triples = annotation['annotations']\n","    num_tokens = sum([len(turn) + 1 for turn in turns])  # +1 for <eos>\n","\n","    # Create vector same size as dialogue\n","    mask_ = np.zeros(num_tokens, dtype=np.uint8)\n","\n","    # Label annotated arguments as BIO tags\n","    for triple in triples:\n","        # if arg == 1:\n","        #     pred = get_predicate_tokens(annotation, triple)\n","        #     if pred is not None:\n","        #         try:\n","        #           pred = pred.strip()\n","        #           pred = pred.strip(\"'\")\n","        #           pred = pred.strip()\n","        #           B_tag, I_tag = lookup[pred]\n","        #         except:\n","        #           B_tag, I_tag = (287,288)\n","\n","        #         for j, (turn_id, token_id) in enumerate(triple[arg]):\n","        #             #print(j, triple[arg])\n","        #             test = sum([len(t) + 1 for t in turns[:turn_id]]) + token_id  # k = index of token in dialogue\n","        #             print(test)\n","        #             if j == 0:\n","        #               mask_[test] = B_tag\n","        #               print(f\"mask k with is: {mask_[test]}, with B-tag {B_tag}\")\n","        #             else:\n","        #               mask_[test] = I_tag\n","        #               print(f\"mask k is: {mask_[test]}, with I-tag {I_tag}\")\n","        # else:\n","          for j, (turn_id, token_id) in enumerate(triple[arg]):\n","              k = sum([len(t) + 1 for t in turns[:turn_id]]) + token_id  # k = index of token in dialogue\n","              mask_[k] = 1 if j == 0 else 2\n","            \n","    return mask_"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":294,"status":"ok","timestamp":1671015143909,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"AMfVIluz8xTA","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"e5bfe7f2-cdf3-48dc-a9e4-e6e12891dc63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      a  pet  might  help  .  SPEAKER1's  dog  calms  SPEAKER1  down  ...  \\\n","subj  1    2      0     0  0           1    2      0         0     0  ...   \n","pred  0    0      1     0  0           0    0      1         0     2  ...   \n","obj   0    0      0     1  0           0    0      0         1     0  ...   \n","\n","      last  year  but  SPEAKER1  still  have  2  cats  .  <eos>  \n","subj     0     0    0         1      0     0  0     0  0      0  \n","pred     0     0    0         0      0     1  0     0  0      0  \n","obj      0     0    0         0      0     0  1     2  0      0  \n","\n","[3 rows x 33 columns]"],"text/html":["\n","  <div id=\"df-ee9317a1-17f1-4017-8f15-4191e7ccb301\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>pet</th>\n","      <th>might</th>\n","      <th>help</th>\n","      <th>.</th>\n","      <th>SPEAKER1's</th>\n","      <th>dog</th>\n","      <th>calms</th>\n","      <th>SPEAKER1</th>\n","      <th>down</th>\n","      <th>...</th>\n","      <th>last</th>\n","      <th>year</th>\n","      <th>but</th>\n","      <th>SPEAKER1</th>\n","      <th>still</th>\n","      <th>have</th>\n","      <th>2</th>\n","      <th>cats</th>\n","      <th>.</th>\n","      <th>&lt;eos&gt;</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>subj</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>pred</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>obj</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 33 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee9317a1-17f1-4017-8f15-4191e7ccb301')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ee9317a1-17f1-4017-8f15-4191e7ccb301 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ee9317a1-17f1-4017-8f15-4191e7ccb301');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["tokens, labels = [], []\n","for ann in annotations:\n","    # Map triple arguments to BIO tagged masks\n","    labels.append((triple_to_bio_tags(ann, 0),\n","                   triple_to_bio_tags(ann, 1),\n","                   triple_to_bio_tags(ann, 2)))\n","    \n","    # Flatten turn sequence\n","    tokens.append([t for ts in ann['tokens'] for t in ts + ['<eos>']])\n","    \n","# Show as BIO scheme\n","i = random.randint(0, len(tokens) - 1)\n","pd.DataFrame(labels[i], columns=tokens[i], index=['subj', 'pred', 'obj'])"]},{"cell_type":"code","source":["i = random.randint(0, len(tokens) - 1)\n","\n","print(tokens[i])\n","print()\n","print(\"token\\tsubj\\tpred\\toj\")\n","for j, token in enumerate(tokens[i]):\n","  print(token, \"\\t\", labels[i][0][j], \"\\t\", labels[i][1][j], \"\\t\", labels[i][2][j])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_X5Hl2yJJ6o","executionInfo":{"status":"ok","timestamp":1671015151138,"user_tz":-60,"elapsed":314,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"6ee57257-c037-45ac-aa7d-b34521797372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['same', 'here', '.', '.', '.', 'lights', 'are', 'out', 'in', \"SPEAKER1's\", 'basement', '.', '.', '.', 'need', 'to', 'call', \"SPEAKER1's\", 'father', '<eos>', 'uh', 'oh', '.', '.', 'maybe', 'SPEAKER1', 'should', 'light', 'some', 'candles', '?', '<eos>', 'SPEAKER1', \"'d\", 'but', 'SPEAKER1', 'do', \"n't\", 'want', 'to', 'summon', 'ghosts', '<eos>']\n","\n","token\tsubj\tpred\toj\n","same \t 0 \t 0 \t 0\n","here \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n","lights \t 1 \t 0 \t 0\n","are \t 0 \t 1 \t 0\n","out \t 0 \t 0 \t 1\n","in \t 0 \t 0 \t 0\n","SPEAKER1's \t 0 \t 0 \t 0\n","basement \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n","need \t 0 \t 1 \t 0\n","to \t 0 \t 2 \t 0\n","call \t 0 \t 0 \t 1\n","SPEAKER1's \t 0 \t 0 \t 2\n","father \t 0 \t 0 \t 2\n","<eos> \t 0 \t 0 \t 0\n","uh \t 0 \t 0 \t 0\n","oh \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n",". \t 0 \t 0 \t 0\n","maybe \t 0 \t 0 \t 0\n","SPEAKER1 \t 1 \t 0 \t 0\n","should \t 0 \t 1 \t 0\n","light \t 0 \t 2 \t 0\n","some \t 0 \t 0 \t 1\n","candles \t 0 \t 0 \t 2\n","? \t 0 \t 0 \t 0\n","<eos> \t 0 \t 0 \t 0\n","SPEAKER1 \t 0 \t 0 \t 0\n","'d \t 0 \t 0 \t 0\n","but \t 0 \t 0 \t 0\n","SPEAKER1 \t 1 \t 0 \t 0\n","do \t 0 \t 0 \t 0\n","n't \t 0 \t 0 \t 0\n","want \t 0 \t 1 \t 0\n","to \t 0 \t 2 \t 0\n","summon \t 0 \t 0 \t 1\n","ghosts \t 0 \t 0 \t 2\n","<eos> \t 0 \t 0 \t 0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9lIqZvzKlDF"},"outputs":[],"source":["import re\n","\n","def bio_tags_to_tokens(tokens, mask, predicate=False, one_hot=False):\n","    \"\"\" Converts a vector of BIO-tags into spans of tokens. If BIO-tags are one-hot encoded,\n","        one_hot=True will first perform an argmax to obtain the BIO labels.\n","\n","        params:\n","        list tokens:    list of subwords or tokens (as tokenized by Albert/AutoTokenizer)\n","        ndarray mask:   list of bio labels (one for each subword or token in 'tokens')\n","        bool one_hot:   whether to interpret mask as a one-hot encoded sequence of shape |sequence|x3\n","    \"\"\"\n","    out = []\n","    span = []\n","    for i, token in enumerate(tokens):\n","        pred = mask[i]\n","\n","        # Reverse one-hot encoding (optional)\n","        if one_hot:\n","            pred = np.argmax(pred)\n","          \n","\n","        if pred %2 == 1:  # B\n","            # if predicate:\n","            #     span = bio_lookup[pred]\n","\n","            # else:\n","              span = re.sub('[^\\w\\d\\-\\']+', ' ', ''.join(span)).strip()\n","              out.append(span)\n","              span = [token]\n","\n","        elif pred != 0 and pred %2 == 0:  # I\n","            if predicate:\n","                continue\n","            else:\n","                span.append(token)\n","\n","    if span:\n","        span = re.sub('[^\\w\\d\\-\\']+', ' ', ''.join(span)).strip()\n","        out.append(span)\n","\n","    # Remove empty strings and duplicates\n","    return set([span for span in out if span.strip()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214,"status":"ok","timestamp":1671015167946,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"KvPSuk30DGOs","outputId":"4bd5e4b0-30af-440d-90ac-a462ab583ebb"},"outputs":[{"output_type":"stream","name":"stdout","text":["not at all . SPEAKER1 got a 3 . 8 . <eos> well , what did SPEAKER1 get in english 101 last year ? <eos> SPEAKER1 got a 4 . 0 in that class . <eos>\n","\n","Subjects:\n","{'SPEAKER1'}\n","\n","Predicates:\n","{'get', 'got'}\n","\n","Objects:\n","{'a 4 0', 'a 3 8'}\n"]}],"source":["i = random.randint(0, len(labels))\n","print(' '.join(tokens[i]) + '\\n')\n","\n","print('Subjects:')\n","print(bio_tags_to_tokens(['+' + t for t in tokens[i]], labels[i][0]))\n","\n","print('\\nPredicates:')\n","print(bio_tags_to_tokens(['+' + t for t in tokens[i]], labels[i][1], predicate=True))\n","\n","print('\\nObjects:')\n","print(bio_tags_to_tokens(['+' + t for t in tokens[i]], labels[i][2]))"]},{"cell_type":"markdown","metadata":{"id":"zmHDBXSdD58b"},"source":["## Setting up ALBERT for Argument Extraction\n","\n","Now we set up ALBERT with a token classification head for each of the arguments. To this end we will use PyTorch to create a small linear classifier for each argument which we can slide over the output of ALBERT to make a prediction for each token. To train other models, you should adapt this code so that it works with your model of choice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTzfnWdmEYE9"},"outputs":[],"source":["%%capture \n","!pip install transformers\n","\n","import torch\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from tqdm import tqdm\n","import numpy as np\n","import random\n","from datetime import date"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RycF3DNjE5zg"},"outputs":[],"source":["class ArgumentExtraction(torch.nn.Module):\n","    def __init__(self, base_model='albert-base-v2', path=None, output_dim=3, sep='<eos>'): # You need to change the output_dim to the total number of BIO-tags (including 0,1,2)\n","        \"\"\" Init model with multi-span extraction heads for SPO arguments.\n","\n","            params:\n","            str base_model: Transformer architecture to use (default: albert-base-v2)\n","            str path:       Path to pretrained model\n","        \"\"\"\n","        super().__init__()\n","        print('loading %s for argument extraction' % base_model)\n","        self._model = AutoModel.from_pretrained(base_model)\n","        self._base = base_model\n","        self._sep = sep\n","\n","        # Load and extend tokenizer with special SPEAKER tokens\n","        self._tokenizer = AutoTokenizer.from_pretrained(base_model)\n","        self._tokenizer.add_tokens(['SPEAKER1', 'SPEAKER2'], special_tokens=True)\n","        self._model.resize_token_embeddings(len(self._tokenizer))\n","\n","        # Add token classification heads\n","        hidden_size = AutoConfig.from_pretrained(base_model).hidden_size\n","        self._subj_head = torch.nn.Linear(hidden_size, output_dim)\n","        self._pred_head = torch.nn.Linear(hidden_size, output_dim)\n","        self._obj_head = torch.nn.Linear(hidden_size, output_dim)\n","        self._output_dim = output_dim\n","\n","        self._relu = torch.nn.ReLU()\n","        self._softmax = torch.nn.Softmax(dim=-1)\n","\n","        # Set GPU if available\n","        self._device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","        self.to(self._device)\n","\n","        # Load model / tokenizer if pretrained model is given\n","        if path:\n","            print('\\t- Loading pretrained')\n","            model_path = path + '/argument_extraction_' + base_model\n","            self.load_state_dict(torch.load(model_path, map_location=self._device))\n","\n","    def forward(self, input_ids, speaker_ids):\n","        \"\"\" Computes BIO label probabilities for each token\n","        \"\"\"\n","        # Feed dialog through transformer\n","        y = self._model(input_ids=input_ids, token_type_ids=speaker_ids)\n","        h = self._relu(y.last_hidden_state)\n","\n","        # Predict spans\n","        y_subj = self._softmax(self._subj_head(h))\n","        y_pred = self._softmax(self._pred_head(h))\n","        y_obj_ = self._softmax(self._obj_head(h))\n","\n","        # Permute output as tensor of shape (N, |C|, seq_len)\n","        y_subj = y_subj.permute(0, 2, 1)\n","        y_pred = y_pred.permute(0, 2, 1)\n","        y_obj_ = y_obj_.permute(0, 2, 1)\n","        return y_subj, y_pred, y_obj_\n","\n","    def _retokenize_tokens(self, tokens):\n","        # Tokenize each token individually (keeping track of subwords)\n","        input_ids = [[self._tokenizer.cls_token_id]]\n","        for t in tokens:\n","            if t != '<eos>':\n","                input_ids.append(self._tokenizer.encode(t, add_special_tokens=False))\n","            else:\n","                input_ids.append([self._tokenizer.eos_token_id])\n","\n","        # Flatten input_ids\n","        f_input_ids = torch.LongTensor([[i for ids in input_ids for i in ids]]).to(self._device)\n","\n","        # Determine how often we need to repeat the labels\n","        repeats = [len(ids) for ids in input_ids]\n","\n","        # Set speaker IDs\n","        speaker_ids = [0] + [tokens[:i + 1].count(self._sep) % 2 for i in range(len(tokens))][:-1]  # TODO: make pretty\n","        speaker_ids = self._repeat_speaker_ids(speaker_ids, repeats)\n","\n","        return f_input_ids, speaker_ids, repeats\n","\n","    def _repeat_speaker_ids(self, speaker_ids, repeats):\n","        \"\"\" Repeats speaker IDs for oov tokens.\n","        \"\"\"\n","        rep_speaker_ids = np.repeat([0] + list(speaker_ids), repeats=repeats)\n","        return torch.LongTensor([rep_speaker_ids]).to(self._device)\n","\n","    def _repeat_labels(self, labels, repeats):\n","        \"\"\" Repeats BIO labels for OOV tokens. Ensure B-labeled tokens are repeated\n","            as B-I-I etc.\n","        \"\"\"\n","        # Repeat each label b the amount of subwords per token\n","        rep_labels = []\n","        for label, rep in zip([0] + list(labels), repeats):\n","            # Outside\n","            if label == 0:\n","                rep_labels += [label] * rep\n","            # Beginning + Inside\n","            elif label == 1:\n","              rep_labels += [label] + ([label+1] * (rep - 1))  # If label = B -> B-I-I-I...\n","            else:\n","                rep_labels += [label] + ([label] * (rep - 1))  # If label = I, do not add 1, but keep the same\n","        return torch.LongTensor([rep_labels]).to(self._device)\n","\n","    def fit(self, tokens, labels, epochs=2, lr=1e-5, weight=3):\n","        \"\"\" Fits the model to the annotations\n","        \"\"\"\n","        #print(\"labels before repeating\")\n","        #print(labels)\n","        # Re-tokenize to obtain input_ids and associated labels\n","        X = []\n","        for token_seq, (subj_labels, pred_labels, _obj_labels) in zip(tokens, labels):\n","            input_ids, speaker_ids, repeats = self._retokenize_tokens(token_seq)\n","            subj_labels = self._repeat_labels(subj_labels, repeats)  # repeat when split into subwords\n","            pred_labels = self._repeat_labels(pred_labels, repeats)\n","            _obj_labels = self._repeat_labels(_obj_labels, repeats)\n","            X.append((input_ids, speaker_ids, subj_labels, pred_labels, _obj_labels))\n","\n","        # Set up optimizer\n","        optim = torch.optim.Adam(self.parameters(), lr=lr)\n","\n","        # Higher weight for B- and I-tags to account for class imbalance\n","        class_weights = torch.Tensor([1] + [weight] * (self._output_dim - 1)).to(self._device)\n","        criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n","\n","        print('Training!')\n","        for epoch in range(epochs):\n","            losses = []\n","            random.shuffle(X)\n","            for input_ids, speaker_ids, subj_y, pred_y, obj_y in tqdm(X):\n","                # Forward pass\n","                subj_y_hat, pred_y_hat, obj_y_hat = self(input_ids, speaker_ids)\n","                #print(subj_y, pred_y, obj_y, subj_y_hat, pred_y_hat, obj_y_hat)\n","                # Compute loss\n","                loss = criterion(subj_y_hat, subj_y)\n","                loss += criterion(pred_y_hat, pred_y)\n","                loss += criterion(obj_y_hat, obj_y)\n","                losses.append(loss.item())\n","\n","                optim.zero_grad()\n","                loss.backward()\n","                optim.step()\n","\n","            print(\"mean loss =\", np.mean(losses))\n","\n","        # Save model to file\n","        torch.save(self.state_dict(), 'argument_extraction_%s' % self._base)\n","\n","    def predict(self, token_seq):\n","        \"\"\" Predicts \"\"\"\n","        # Retokenize token sequence\n","        input_ids, speaker_ids, _ = self._retokenize_tokens(token_seq)\n","\n","        # Invert tokenization for viewing\n","        subwords = self._tokenizer.convert_ids_to_tokens(input_ids[0])\n","\n","        # Forward-pass\n","        predictions = self(input_ids, speaker_ids)\n","        subjs = predictions[0].cpu().detach().numpy()[0]\n","        preds = predictions[1].cpu().detach().numpy()[0]\n","        objs = predictions[2].cpu().detach().numpy()[0]\n","\n","        return subjs, preds, objs, subwords"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443,"referenced_widgets":["db9506adfd6049ef944efee21df2a9df","70c27d97c0e8405fa37bae0bd85295a9","93fabb0e7fc84bd2abbe8169a56fdd8c","77a5ab39232048899e83826fe94d9340","29b49cd55ca44a91b1c52d170f1e688a","dc5f44b3b8994a8283a1e0ef51e7bedb","75541f6a7456470eb40d2f44d8f81dcd","0d06ed96d7954b68b5f51955ab0a5e78","5973d4e85b8c4677ba86c614b7e82f5a","7fba6ab1e8b14dcf91a47a47aa3268f2","4c093a96fc1a480580038924c00399e6","872243ded5a6448e82636a58336ff065","d6f0d2664d294768bf364013f3dcd9ed","4a2aaa3154fe4503a7e6956790e1953c","c32812ae022d4e48aef8fbf372062230","3c013369960c46aebf85526075594686","f375de562b9f4f6e9f4c71b0e1c72c4b","275df89cb1be4682bdca87d2ee427bfc","69cec72d603f42eab551aeea510a829a","baa99d837c3b4b76a500198d42a45316","411b500460da4ee2873368851c375016","1fb8160b9ec747568077595f4e0dbb9b","28488812e2194f5d8b1d223225da4c44","c1aac2da00424f668f6143072f6cbb40","dd87c1eb131f444882ed26be2c0560ea","7a71c5e007e84172ad7f48999311d4e1","7d736a276c1848328e2528b8c6666f21","92edb21e1dbf412a81fcd715cef7aed7","d3dac2ba3e844a1c8113500f6d4b173a","dc2c51bac2944000b01542ce45c12273","bf10223bf5e5465db18f96b65a506d65","927038389972430389bab43e6782767e","6423e83cbf68426294e8363b205ec655","6a4ef63326e7446a92e6d08b287713bf","9a94907d95684179882d443375ea4e21","5ce288934bee4126bc527731d12bffa6","42c66435b0f144caaa5404d0225b78ed","0a2931959a2b450793d3a5e60b3f93d3","0bd0ea686e384d99ba08d8585113f30b","7c120bf86e29457e8fc5bafd334d2fc4","08d4757bfbb74f0a8b552fcfabb574d4","d79b6f122880498e8ec80d9a740d613b","9a908e1f12174a2399a333188399979d","970c57dc8e944a3abe89e695b483e383"]},"executionInfo":{"elapsed":244344,"status":"ok","timestamp":1671015461793,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"8YSOXXZ-8aW2","outputId":"7a81be79-b6be-4605-dbe2-d4a3795e58ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading albert-base-v2 for argument extraction\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9506adfd6049ef944efee21df2a9df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"872243ded5a6448e82636a58336ff065"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28488812e2194f5d8b1d223225da4c44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a4ef63326e7446a92e6d08b287713bf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-6da54b737b17>:83: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n","  return torch.LongTensor([rep_speaker_ids]).to(self._device)\n"]},{"output_type":"stream","name":"stdout","text":["Training!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1117/1117 [00:46<00:00, 24.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 2.0148611808314105\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1117/1117 [00:35<00:00, 31.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 1.8831506366695585\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1117/1117 [00:36<00:00, 30.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 1.8629916325785159\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1117/1117 [00:35<00:00, 31.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 1.844103985421873\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1117/1117 [00:38<00:00, 29.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 1.8267154453477372\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1117/1117 [00:36<00:00, 30.74it/s]"]},{"output_type":"stream","name":"stdout","text":["mean loss = 1.8201741939585658\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["#CUDA_LAUNCH_BLOCKING=1\n","model = ArgumentExtraction(output_dim=3)  \n","model.fit(tokens, labels, epochs=6)"]},{"cell_type":"code","source":["#load already trained model here\n","\n","# argex_model = ArgumentExtraction(path=root_dir+'/models/baseline2022-12-09')"],"metadata":{"id":"AS849JZzUyA6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670864389291,"user_tz":-60,"elapsed":3840,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"4a4d32a2-b6ef-4b27-a6f8-0697dacbff59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading albert-base-v2 for argument extraction\n","\t- Loading pretrained\n"]}]},{"cell_type":"code","source":["import os, shutil\n","\n","# out_dir = root_dir + '/models/' + str(date.today())\n","out_dir = root_dir + '/models/' + 'baseline' + str(date.today())\n","if not os.path.exists(out_dir):\n","    os.mkdir(out_dir)\n","\n","shutil.copy('argument_extraction_albert-base-v2', out_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VHPHtLuZOpLt","executionInfo":{"status":"ok","timestamp":1671015467722,"user_tz":-60,"elapsed":218,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"36125cb5-9065-42bf-c24d-ae102f6ee2be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/Communicative Robotics/models/baseline2022-12-14/argument_extraction_albert-base-v2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"VU9wc9r0E8K3"},"source":["## Putting It All Together\n","\n","Below you can see the token assignments with the BIO scheme to SPO arguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnAHMx4jUzM4"},"outputs":[],"source":["# inputs_example = 'What car do SPEAKER1 drive <eos> a big red truck <eos>'.split()\n","# print(inputs_example)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2716,"status":"ok","timestamp":1670864405727,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"ZAVqUvidP60K","outputId":"10328004-6e03-4851-a166-ea670548e91e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["first utterance in tokens: ['good', 'morning', '.', '<eos>', 'what', \"'s\", 'the', 'problem', '?', '<eos>', 'i', \"'m\", 'running', 'a', 'high', 'fever', 'and', 'feeling', 'terribly', 'bad', '.']\n","first utterance in tokens with speaker disambiguation: ['good', 'morning', '.', '<eos>', 'what', \"'s\", 'the', 'problem', '?', '<eos>', 'SPEAKER1', \"'m\", 'running', 'a', 'high', 'fever', 'and', 'feeling', 'terribly', 'bad', '.']\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","\n","file = load_evaluation_data(root_dir + '/annotated_data/evaluatiedata/test_declarative_statements_abstract_val_l1.txt')\n","inputs = ''\n","\n","string = '<eos>'\n","space = ' '\n","\n","inputs = []\n","for row in file:\n","  if row.find('<eos>') >= 0:\n","    row = row.replace(string, space + string + space)\n","    all_tokens = []\n","    speaker_utterances = row.split('<eos>') #lijst met strings, elke string is een zin van 1 speaker\n","    for utt in speaker_utterances:\n","      tokens = [token.lower() for token in word_tokenize(utt)]\n","      tokens.append('<eos>')\n","      for token in tokens:\n","        all_tokens.append(token)\n","    #tokens = [token.lower() for token in word_tokenize(row)]\n","    #words = row.split()\n","    all_tokens.pop()\n","    inputs.append(all_tokens)\n","\n","print(\"first utterance in tokens:\", inputs[0])\n","\n","#speaker disambiguation\n","disambig_inputs = []\n","for utterance in inputs:\n","  disambig_utterance = []\n","  turn_counter = 0\n","  for token in utterance:\n","    if token == '<eos>':\n","      turn_counter +=1\n","    disambig_utterance.append(disambiguate_pronouns(token, turn_counter))\n","  disambig_inputs.append(disambig_utterance)\n","\n","print(\"first utterance in tokens with speaker disambiguation:\", disambig_inputs[0])"]},{"cell_type":"code","source":["for utterance in disambig_inputs[:10]:\n","  print(utterance)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Rs25Di06csA","executionInfo":{"status":"ok","timestamp":1670592878349,"user_tz":-60,"elapsed":328,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"a06f9e23-607c-46e1-a30f-705eab421785"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['good', 'morning', '.', '<eos>', 'what', \"'s\", 'the', 'problem', '?', '<eos>', 'SPEAKER1', \"'m\", 'running', 'a', 'high', 'fever', 'and', 'feeling', 'terribly', 'bad', '.']\n","['haha', 'yeah', ',', 'SPEAKER1', 'like', 'football', 'and', 'country', 'music', '<eos>', 'sounds', 'like', 'SPEAKER1', 'are', 'from', 'the', 'south', ',', 'what', 'is', \"SPEAKER1's\", 'favorite', 'team', '?', '<eos>', 'the', 'colts', ',', 'from', \"SPEAKER1's\", 'home', 'state']\n","['yes', ',', 'it', \"'s\", 'SPEAKER1', '.', '<eos>', 'do', 'SPEAKER1', 'have', 'a', 'cold', '?', '<eos>', 'no', '.', 'worse', 'than', 'that', '.', 'SPEAKER1', 'have', 'a', 'flu', '.', 'SPEAKER1', \"'m\", 'in', 'bed', 'with', 'a', 'fever', '.']\n","['alot', 'really', ',', 'SPEAKER1', 'enjoy', 'going', 'out', 'to', 'eat', 'with', 'family', ',', 'going', 'to', 'the', 'movies', '<eos>', 'have', 'SPEAKER1', 'been', 'to', 'the', 'movies', 'lately', '?', '<eos>', 'yes', ',', 'SPEAKER1', 'go', 'a', 'couple', 'of', 'times', 'a', 'month', '.']\n","['what', 'is', \"SPEAKER2's\", 'favorite', 'pizza', 'toppings', '?', '<eos>', 'SPEAKER2', 'like', 'mushroom', 'and', 'spinach', 'what', 'about', 'SPEAKER1', '?', '<eos>', 'same', ',', 'with', 'feta', 'cheese', 'and', 'onions']\n","['grandma', 'babysits', 'she', \"'s\", 'a', 'lawyer', '<eos>', 'she', 'must', 'be', 'really', 'progressive', 'if', 'she', \"'s\", 'a', 'laywer', ',', 'what', 'do', 'SPEAKER1', 'do', '?', '<eos>', 'SPEAKER1', 'like', 'to', 'dance', 'on', 'the', 'weekends']\n","['that', 'would', 'be', 'a', 'very', 'interesting', 'job', '<eos>', 'yes', ',', 'SPEAKER2', \"'d\", 'be', 'around', 'art', '.', 'painting', 'is', \"SPEAKER2's\", 'hobby', '.', 'how', 'about', 'SPEAKER1', '?', '<eos>', 'SPEAKER1', 'love', 'to', 'run', 'and', 'that', 'keeps', 'SPEAKER1', 'in', 'shape']\n","['they', \"'re\", 'doing', 'good', '.', 'SPEAKER1', \"'m\", 'the', 'one', 'who', 'feels', 'lost', 'in', 'who', 'SPEAKER1', 'am', '.', '<eos>', 'why', 'is', 'that', '?', 'why', 'do', 'SPEAKER1', 'feel', 'lost', '?', '<eos>', 'SPEAKER1', 'have', 'a', 'good', 'relationship', 'with', \"SPEAKER1's\", 'husband', 'but', 'feel', 'alone', 'sometimes', '.']\n","['that', 'kind', 'of', 'work', 'does', 'take', 'creativity', '.', 'SPEAKER1', 'am', 'not', 'that', 'fortunate', '.', '<eos>', 'does', \"SPEAKER1's\", 'work', 'require', 'creativity', '?', '<eos>', 'it', \"'s\", 'mostly', 'busywork', '.']\n","['nope', 'SPEAKER1', 'like', 'all', 'books', 'but', \"SPEAKER1's\", 'last', 'one', 'was', 'lord', 'of', 'the', 'flies', '<eos>', 'do', 'SPEAKER1', 'like', 'lord', 'of', 'the', 'rings', '?', '<eos>', 'yes', ',', 'the', 'movies', 'are', 'excellent', '.']\n"]}]},{"cell_type":"markdown","source":["##predictions en validatie"],"metadata":{"id":"t2pF0CiRS5gX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3594,"status":"ok","timestamp":1670864453217,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"vA_k8BgQ0iJu","outputId":"19b5b6dd-8453-47a0-d28f-2c338b5d3dbc"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-6da54b737b17>:83: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n","  return torch.LongTensor([rep_speaker_ids]).to(self._device)\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Subject\n","\t\t0\t1\t2\t3\t4\t5\t6\n","[CLS] \t\t [0.998]\t 0.000 \t 0.000 \n","good \t\t [0.999]\t 0.000 \t 0.000 \n","morning \t\t [0.999]\t 0.000 \t 0.000 \n"," \t\t [0.999]\t 1e-04 \t 0.000 \n",". \t\t [0.999]\t 0.000 \t 0.000 \n","[SEP] \t\t [0.998]\t 0.001 \t 0.001 \n","what \t\t [0.999]\t 0.000 \t 0.000 \n"," \t\t [0.997]\t 0.000 \t 0.001 \n","' \t\t [0.995]\t 0.001 \t 0.002 \n","s \t\t [0.994]\t 0.002 \t 0.002 \n","the \t\t  0.001 \t[0.997]\t 0.001 \n","problem \t\t  0.008 \t 0.007 \t[0.983]\n"," \t\t [0.999]\t 1e-04 \t 1e-04 \n","? \t\t [0.999]\t 0.000 \t 0.000 \n","[SEP] \t\t [0.998]\t 0.001 \t 0.001 \n","SPEAKER1 \t\t  0.000 \t[0.999]\t 0.000 \n"," \t\t [0.997]\t 0.000 \t 0.002 \n","' \t\t [0.997]\t 0.001 \t 0.001 \n","m \t\t [0.998]\t 0.000 \t 0.000 \n","running \t\t [0.997]\t 0.000 \t 0.001 \n","a \t\t [0.990]\t 0.008 \t 0.001 \n","high \t\t [0.998]\t 0.000 \t 0.001 \n","fever \t\t [0.998]\t 0.000 \t 0.001 \n","and \t\t [0.999]\t 0.000 \t 0.000 \n","feeling \t\t [0.997]\t 0.000 \t 0.001 \n","terribly \t\t [0.995]\t 0.003 \t 0.001 \n","bad \t\t [0.998]\t 0.000 \t 0.000 \n"," \t\t [0.999]\t 0.000 \t 0.000 \n",". \t\t [0.999]\t 0.000 \t 0.000 \n","\n"," Predicate\n","\t\t0\t1\t2\t3\t4\t5\t6\n","[CLS] \t\t [0.998]\t 0.000 \t 0.000 \n","good \t\t [0.999]\t 0.000 \t 1e-04 \n","morning \t\t [0.999]\t 0.000 \t 0.000 \n"," \t\t [0.999]\t 0.000 \t 0.000 \n",". \t\t [0.999]\t 0.000 \t 0.000 \n","[SEP] \t\t [0.996]\t 0.001 \t 0.002 \n","what \t\t [0.995]\t 0.002 \t 0.002 \n"," \t\t  0.006 \t[0.980]\t 0.013 \n","' \t\t  0.001 \t 0.001 \t[0.997]\n","s \t\t  0.001 \t 0.001 \t[0.997]\n","the \t\t [0.998]\t 0.000 \t 0.000 \n","problem \t\t [0.994]\t 0.003 \t 0.001 \n"," \t\t [0.999]\t 0.000 \t 0.000 \n","? \t\t [0.999]\t 0.000 \t 0.000 \n","[SEP] \t\t [0.996]\t 0.001 \t 0.002 \n","SPEAKER1 \t\t [0.998]\t 0.001 \t 0.000 \n"," \t\t  0.121 \t[0.858]\t 0.020 \n","' \t\t  0.076 \t 0.013 \t[0.909]\n","m \t\t  0.447 \t 0.033 \t[0.519]\n","running \t\t  0.001 \t[0.990]\t 0.008 \n","a \t\t [0.985]\t 0.001 \t 0.012 \n","high \t\t [0.994]\t 0.001 \t 0.004 \n","fever \t\t [0.996]\t 0.000 \t 0.003 \n","and \t\t [0.999]\t 0.000 \t 0.000 \n","feeling \t\t  0.000 \t[0.997]\t 0.001 \n","terribly \t\t [0.980]\t 0.003 \t 0.015 \n","bad \t\t [0.991]\t 0.000 \t 0.007 \n"," \t\t [0.999]\t 0.000 \t 0.000 \n",". \t\t [0.999]\t 0.000 \t 0.000 \n","\n"," Object\n","\t\t0\t1\t2\t3\t4\t5\t6\n","[CLS] \t\t [0.998]\t 0.000 \t 0.000 \n","good \t\t [0.998]\t 0.001 \t 0.000 \n","morning \t\t [0.997]\t 0.001 \t 0.001 \n"," \t\t [0.999]\t 0.000 \t 0.000 \n",". \t\t [0.999]\t 0.000 \t 0.000 \n","[SEP] \t\t [0.995]\t 0.002 \t 0.002 \n","what \t\t [0.996]\t 0.003 \t 0.000 \n"," \t\t [0.996]\t 0.001 \t 0.002 \n","' \t\t [0.987]\t 0.004 \t 0.007 \n","s \t\t [0.990]\t 0.003 \t 0.005 \n","the \t\t [0.940]\t 0.056 \t 0.003 \n","problem \t\t [0.743]\t 0.010 \t 0.245 \n"," \t\t [0.999]\t 0.000 \t 0.000 \n","? \t\t [0.999]\t 0.000 \t 0.000 \n","[SEP] \t\t [0.995]\t 0.002 \t 0.002 \n","SPEAKER1 \t\t [0.990]\t 0.008 \t 0.001 \n"," \t\t [0.995]\t 0.001 \t 0.003 \n","' \t\t [0.994]\t 0.002 \t 0.003 \n","m \t\t [0.998]\t 0.000 \t 0.000 \n","running \t\t [0.996]\t 0.002 \t 0.001 \n","a \t\t  0.000 \t[0.998]\t 0.000 \n","high \t\t  0.000 \t 0.001 \t[0.998]\n","fever \t\t  0.000 \t 0.000 \t[0.998]\n","and \t\t [0.999]\t 0.000 \t 0.000 \n","feeling \t\t [0.996]\t 0.001 \t 0.001 \n","terribly \t\t  0.003 \t[0.995]\t 0.001 \n","bad \t\t  0.001 \t 0.012 \t[0.986]\n"," \t\t [0.999]\t 0.000 \t 0.000 \n",". \t\t [0.999]\t 0.000 \t 0.000 \n"]}],"source":["y_subj, y_pred, y_obj, subwords = argex_model.predict(disambig_inputs[0])\n","\n","# show results\n","for arg, y in [('Subject', y_subj), ('Predicate', y_pred), ('Object', y_obj)]:\n","    print('\\n', arg)\n","    print('\\t\\t0\\t1\\t2\\t3\\t4\\t5\\t6')\n","    for score, token in zip(y.T, subwords):\n","        score_str = '\\t'.join([\"[\" + str(s)[:5] + \"]\" if s == max(score) else \" \" + str(round(s, 4))[:5] + \" \" for s in score])\n","        token_str = token.replace('▁', '')\n","        print(token_str, '\\t\\t', score_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2287,"status":"ok","timestamp":1670864479170,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"},"user_tz":-60},"id":"El26oCJcE-_F","outputId":"ef2827e3-49ec-42f6-cde5-c5d30ac40c6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] good morning  . [SEP] what  ' s the problem  ? [SEP] SPEAKER1  ' m running a high fever and feeling terribly bad  .\n","\n","Subjects:   {'the problem', 'SPEAKER1'}\n","Predicates: {'feeling', 'running'}\n","Objects:    {'a high fever', 'terribly bad'}\n","\n","[CLS] ha ha yeah  , SPEAKER1 like football and country music [SEP] sounds like SPEAKER1 are from the south  , what is SPEAKER1  ' s favorite team  ? [SEP] the colts  , from SPEAKER1  ' s home state\n","\n","Subjects:   {'SPEAKER1', \"SPEAKER1 's favorite\"}\n","Predicates: {'like', 'is', 'are'}\n","Objects:    {'country music', 'the south team', \"SPEAKER1 's home state\", 'football', 'the colts'}\n","\n","[CLS] yes  , it  ' s SPEAKER1  . [SEP] do SPEAKER1 have a cold  ? [SEP] no  . worse than that  . SPEAKER1 have a flu  . SPEAKER1  ' m in bed with a fever  .\n","\n","Subjects:   {'SPEAKER1', 'it'}\n","Predicates: {'worse', 'have'}\n","Objects:    {'a cold', 'that', 'SPEAKER1', 'a fever', 'a flu'}\n","\n","[CLS] a lot really  , SPEAKER1 enjoy going out to eat with family  , going to the movies [SEP] have SPEAKER1 been to the movies lately  ? [SEP] yes  , SPEAKER1 go a couple of times a month  .\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'enjoy', 'been', 'going'}\n","Objects:    {'eat with family', 'the movies', 'a couple of times a month'}\n","\n","[CLS] what is SPEAKER2  ' s favorite pizza to pping s  ? [SEP] SPEAKER2 like mushroom and spin ach what about SPEAKER1  ? [SEP] same  , with fe ta cheese and on ions\n","\n","Subjects:   {\"SPEAKER2 's favorite pizza to\", 'SPEAKER2'}\n","Predicates: {'like', 'is'}\n","Objects:    {'feta cheese', 'mushroom', 'same', 'onions', 'spinach', 'pizza toppings'}\n","\n","[CLS] grandma baby s its she  ' s a lawyer [SEP] she must be really progressive if she  ' s a lay wer  , what do SPEAKER1 do  ? [SEP] SPEAKER1 like to dance on the weekends\n","\n","Subjects:   {'SPEAKER1', 'she'}\n","Predicates: {'like', 'must'}\n","Objects:    {'dance on', 'a laywer', 'a lawyer', 'the weekends', 'really progressive'}\n","\n","[CLS] that would be a very interesting job [SEP] yes  , SPEAKER2  ' d be around art  . painting is SPEAKER2  ' s hobby  . how about SPEAKER1  ? [SEP] SPEAKER1 love to run and that keeps SPEAKER1 in shape\n","\n","Subjects:   {'painting', 'SPEAKER1', 'that', 'SPEAKER2'}\n","Predicates: {'be', 'keeps', 'is', 'love'}\n","Objects:    {'a very interesting job', \"SPEAKER2 's hobby\", 'art', 'shape', 'run'}\n","\n","[CLS] they  ' re doing good  . SPEAKER1  ' m the one who feels lost in who SPEAKER1 am  . [SEP] why is that  ? why do SPEAKER1 feel lost  ? [SEP] SPEAKER1 have a good relationship with SPEAKER1  ' s husband but feel alone sometimes  .\n","\n","Subjects:   {'SPEAKER1', 'they'}\n","Predicates: {'feel', 'doing', 'have'}\n","Objects:    {\"a good relationship withSPEAKER1 's husband\", 'alone', 'good', 'whoSPEAKER1 am', 'the one who feels', 'lost'}\n","\n","[CLS] that kind of work does take creativity  . SPEAKER1 am not that fortunate  . [SEP] does SPEAKER1  ' s work require creativity  ? [SEP] it  ' s mostly busy work  .\n","\n","Subjects:   {'SPEAKER1', \"SPEAKER1 's work\", 'that kind of work', 'it'}\n","Predicates: {'require', 'am', 'take'}\n","Objects:    {'creativity', 'that fortunate', 'of', 'busywork'}\n","\n","[CLS]  nope SPEAKER1 like all books but SPEAKER1  ' s last one was lord of the flies [SEP] do SPEAKER1 like lord of the rings  ? [SEP] yes  , the movies are excellent  .\n","\n","Subjects:   {'SPEAKER1', 'the movies', \"SPEAKER1 's last one\"}\n","Predicates: {'like', 'was', 'are'}\n","Objects:    {'lord of the flies', 'excellent', 'all books', 'lord of the rings'}\n","\n","[CLS] SPEAKER1  ' ll probably end up going to the gym  . have any animals  ? [SEP] no  , SPEAKER2  ' m only in college  . what do SPEAKER1 do  ? [SEP] in between jobs right now so SPEAKER2 can find SPEAKER1 on the tread mill or rowing machine  .\n","\n","Subjects:   {'SPEAKER1', 'SPEAKER2'}\n","Predicates: {'can', 'end', 'in', 'have', 'do'}\n","Objects:    {'college', 'jobs right', 'animals', 'rowing machine', 'the treadmill', 'SPEAKER1', 'the gym'}\n","\n","[CLS] true love is the strongest magic  . SPEAKER1 hope SPEAKER2  ' s family can understand someday  . [SEP] is SPEAKER1  ' s family doing well  ? [SEP] yes  , SPEAKER1 are all really content ed at the moment  .\n","\n","Subjects:   {\"SPEAKER1 's family\", 'SPEAKER1', 'true', \"SPEAKER2 's family\"}\n","Predicates: {'doing', 'can', 'love', 'content', 'are'}\n","Objects:    {'well', 'the strongest magic', 'someday', 'the moment'}\n","\n","[CLS] that  ' s cool  . what state do SPEAKER2 live in  ? [SEP] SPEAKER2 live on the west coast what about SPEAKER1  ? [SEP] SPEAKER1 live in north carolina  . SPEAKER1 never been to the west coast  .\n","\n","Subjects:   {'SPEAKER1', 'that', 'SPEAKER2'}\n","Predicates: {'been', 'live'}\n","Objects:    {'cool', 'the west coast', 'north carolina'}\n","\n","[CLS] it  ' s going good just playing some video games before bed [SEP] sounds like fun  ! SPEAKER1 play often  ? [SEP] yes SPEAKER1 play every day SPEAKER1  ' ve never had a job and in school\n","\n","Subjects:   {'SPEAKER1', 'it'}\n","Predicates: {'had', 'play', 'sounds', 'going', 'playing'}\n","Objects:    {'good', 'every day', 'a job', 'fun', 'some video games before bed', 'school'}\n","\n","[CLS] they work as big banker s  . [SEP] that  s cool  , is that what SPEAKER1 wan na do as well  ? [SEP] yes SPEAKER1 think that  ' s what SPEAKER1  ' ll be doing  .\n","\n","Subjects:   {'SPEAKER1', 'that', 'they'}\n","Predicates: {'wan', 'work'}\n","Objects:    {'cool', 'big bankers', 'what'}\n","\n","[CLS] SPEAKER1 enjoy them as well  . favorite are action movies  ! [SEP] do SPEAKER1 like action movies  ? [SEP] SPEAKER1 love them\n","\n","Subjects:   {'SPEAKER1', 'favorite'}\n","Predicates: {'like', 'enjoy', 'love', 'are'}\n","Objects:    {'them', 'action movies'}\n","\n","[CLS] SPEAKER1 love the birds and SPEAKER1  ' s cats  . [SEP] how many do SPEAKER1 have  ? [SEP] SPEAKER1  ' ve two cats  . SPEAKER1 watch the birds outside  . it is getting close to holidays  .\n","\n","Subjects:   {'SPEAKER1', 'it'}\n","Predicates: {'watch', 'have', 'love', 'getting'}\n","Objects:    {\"SPEAKER1 's cats\", 'holidays', 'the birds outside', 'the birds', 'two cats'}\n","\n","[CLS] SPEAKER1 love to grill outdoor s  . maybe SPEAKER2 can come visit for dinner  . [SEP] do SPEAKER1 want to get dinner  ? [SEP] no\n","\n","Subjects:   {'SPEAKER1', 'SPEAKER2'}\n","Predicates: {'want', 'can', 'love'}\n","Objects:    {'get dinner', 'grill outdoors', 'dinner'}\n","\n","[CLS] that is cool what kind of food do SPEAKER2 like [SEP] want to eat some spicy food  ? [SEP] SPEAKER1 might as well\n","\n","Subjects:   {'SPEAKER1', 'that', 'SPEAKER2'}\n","Predicates: {'like', 'might', 'want', 'is'}\n","Objects:    {'cool', 'eat some spicy food'}\n","\n","[CLS] SPEAKER1 am trying to write a book while SPEAKER1 work in SPEAKER1  ' s garden ing [SEP] do SPEAKER1 prefer to hold a book  ? [SEP] no\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'prefer', 'work', 'trying'}\n","Objects:    {'write a book', 'hold a book', \"SPEAKER1 's gardening\"}\n","\n","[CLS] SPEAKER1  ' m afraid there is  n ' t  . SPEAKER1  ' s boss only pays lip service  . [SEP] what is SPEAKER1  ' s salary expectation for this position  ? [SEP] SPEAKER1  ' s expectation is in the 3 800 to 4 500 rib range  . that  ' s the take home pay  .\n","\n","Subjects:   {\"SPEAKER1 's boss\", 'there', \"SPEAKER1 's expectation\", 'that', \"SPEAKER1 's salary\"}\n","Predicates: {'pays', 'expectation', 'is'}\n","Objects:    {'lip service', 'this position', 'the take home pay', 'the 3800 to 4500 rib range'}\n","\n","[CLS] well  , that was an intelligent thing to do  . [SEP] SPEAKER1 do  n ' t have any spare change  ? [SEP] no  , SPEAKER1 do  n ' t  .\n","\n","Subjects:   {'SPEAKER1', 'that'}\n","Predicates: {'have', 'was'}\n","Objects:    {'an intelligent thing to do', 'spare change'}\n","\n","[CLS] she buy s SPEAKER1 what SPEAKER1 want when SPEAKER1 want  . SPEAKER1 do not want to work  . [SEP] that  ' s not a good attitude to have  . SPEAKER1 do not want SPEAKER1  ' s own money  ? [SEP] SPEAKER1  ' m ease dropping on SPEAKER1  ' s neighbors they are fighting  lol\n","\n","Subjects:   {'SPEAKER1', 'that', 'she'}\n","Predicates: {'buy', 'want', 'dropping', 'are'}\n","Objects:    {'what', \"SPEAKER1 's own money\", 'a good attitude to have', \"SPEAKER1 's neighbors\", 'fighting', 'SPEAKER1', 'work', 'ease'}\n","\n","[CLS] since SPEAKER1 was fired SPEAKER1 found a job in insurance  . [SEP] what is the pay like  ? [SEP] it is ok  , but SPEAKER1  ' s dad made a  ton before he passed away  .\n","\n","Subjects:   {'he', 'the pay like', 'SPEAKER1', \"SPEAKER1 's dad\", 'it'}\n","Predicates: {'is', 'was', 'passed', 'made', 'found'}\n","Objects:    {'ok', 'away', 'a job in insurance', 'fired', 'a ton'}\n","\n","[CLS] thanks  . SPEAKER1  ' ll try to check it out  . SPEAKER1 hope SPEAKER2 have a good day [SEP] did SPEAKER1 have a good day  ? [SEP] SPEAKER1  ' s day was annoying  .\n","\n","Subjects:   {\"SPEAKER1 's day\", 'SPEAKER1', 'SPEAKER2'}\n","Predicates: {'have', 'was', 'try'}\n","Objects:    {'a good day', 'annoying', 'check it out'}\n","\n","[CLS] SPEAKER1 work at an india restaurant  . [SEP] do SPEAKER1 want to go out to a restaurant  ? [SEP] yes\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'want', 'work'}\n","Objects:    {'go out', 'an india restaurant', 'a restaurant'}\n","\n","[CLS] it was hard at the beginning  , but now feel it  ' s really relaxing  . it makes SPEAKER1 flexible  . [SEP] anything else  ? [SEP] yes  , SPEAKER1 often go swimming  .\n","\n","Subjects:   {'SPEAKER1', 'it'}\n","Predicates: {'feel', 'was', 'go', 'makes'}\n","Objects:    {'the beginning', 'swimming', 'flexible', 'really relaxing', 'it'}\n","\n","[CLS] SPEAKER1 do  n ' t have a job  . SPEAKER1 am a college student  . [SEP] do SPEAKER1 need a college degree for the job  ? [SEP] yes\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'have', 'am', 'need'}\n","Objects:    {'a job', 'a college student', 'a college degree for the job'}\n","\n","[CLS] good  , getting ready for SPEAKER1  ' s gig tonight SPEAKER1 am a singer and SPEAKER1 love it  ! [SEP] what kind of music do SPEAKER1 sing  ? [SEP] rock  . SPEAKER1 usually do gig s on saturday s but a job is a job  .\n","\n","Subjects:   {'a job', 'SPEAKER1'}\n","Predicates: {'sing', 'love', 'is', 'getting', 'am', 'do'}\n","Objects:    {'a singer', 'a job', 'rock', \"SPEAKER1 's gig\", 'gigs on saturdays job', 'it'}\n","\n","[CLS] SPEAKER1 am going to a concert and maybe try the new italian place after  . [SEP] oh  , great  ! what kind of concert  ? what kind of music  ? [SEP] 5 star symphony  , its orchestra  .\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'try', 'going'}\n","Objects:    {'its orchestra', 'a concert', 'the new italian place after', '5 star symphony'}\n","\n","[CLS] SPEAKER1 enjoy it but when SPEAKER1 do go out with friends no italian food please [SEP] do SPEAKER1 like italian food  ? [SEP] it  ' s the best  .\n","\n","Subjects:   {'SPEAKER1', 'it'}\n","Predicates: {'like', 'enjoy', 'go'}\n","Objects:    {'italian food', 'the best', 'friends no italian food', 'it'}\n","\n","[CLS] or discuss what gifts they could buy together  . [SEP] any other ideas  ? [SEP] SPEAKER1 can also put a guest book on the website for people to sign and write comments  .\n","\n","Subjects:   {'SPEAKER1', 'they'}\n","Predicates: {'can', 'could', 'discuss', 'write'}\n","Objects:    {'a guest book', 'the website for people to sign', 'comments', 'together', 'what gifts'}\n","\n","[CLS] there are some seats in the rear m ezza nine  . [SEP] is  n ' t there anything else available  ? [SEP] no  , the show is nearly sold out  .\n","\n","Subjects:   {'there', 'the show'}\n","Predicates: {'sold', 'is', 'are'}\n","Objects:    {'anything else available', 'sold', 'some', 'the rear mezzanine'}\n","\n","[CLS] do SPEAKER2 know anyone who is single  ? [SEP] are SPEAKER1 a boy or girl  ? [SEP] SPEAKER1 am a female who works out\n","\n","Subjects:   {'SPEAKER1', 'SPEAKER2'}\n","Predicates: {'know', 'am', 'are'}\n","Objects:    {'girl', 'anyone who is single', 'a female who works out', 'a boy'}\n","\n","[CLS] SPEAKER1 am currently a cleaning lady and do a lot of work in the city  . [SEP] were SPEAKER1 born in this city  ? [SEP] no  , SPEAKER1 was born in the countryside\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'born', 'was', 'am', 'do'}\n","Objects:    {'alot of', 'the countryside', 'this city', 'the city', 'a cleaning lady'}\n","\n","[CLS] yes  , SPEAKER1 have both the paperback and hardcover  . which would SPEAKER2 want to buy  ? [SEP] how about the price of the hardcover  ? [SEP] it  ' s 25  .\n","\n","Subjects:   {'SPEAKER1', 'the of the hardcover', 'SPEAKER2', 'it'}\n","Predicates: {'have', 'want'}\n","Objects:    {'the paperback', 'buy price of the hardcover', '25', 'hardcover'}\n","\n","[CLS] probably going to  th rif t stores  . [SEP] shopping is okay  . what is SPEAKER1  ' s favorite thing to shop for  ? [SEP] fun toys for SPEAKER1  ' s niece s  .\n","\n","Subjects:   {\"SPEAKER1 's favorite thing shop\", 'shopping'}\n","Predicates: {'is', 'going'}\n","Objects:    {'okay thing to shop for', \"fun toys forSPEAKER1 's nieces\", 'thrift stores'}\n","\n","[CLS] did SPEAKER2 learn about people with 3 to es  ? [SEP] no  . are SPEAKER1 a slo th  ? [SEP] no  . SPEAKER1 am a person  . do not be rude  . SPEAKER1 will feed SPEAKER2 to the lions  .\n","\n","Subjects:   {'SPEAKER1', 'SPEAKER2'}\n","Predicates: {'learn', 'will', 'are', 'feed', 'be', 'am'}\n","Objects:    {'rude', 'a sloth', 'the lions', 'a person', 'people with 3 toes'}\n","\n","[CLS] hi there  , SPEAKER1 decided to pack up SPEAKER1  ' s belonging s and move here from germany  . [SEP] has SPEAKER1  ' s move been easy  ? [SEP] it  ' s been problem free  .\n","\n","Subjects:   {'SPEAKER1', \"SPEAKER1 's move\", 'it'}\n","Predicates: {'decided', 'move', 'been'}\n","Objects:    {\"pack upSPEAKER1 's belongings\", 'problem free', 'easy', 'germany'}\n","\n","[CLS]  y up been to new york city 3 times this year [SEP] do SPEAKER1 want to live in new york city  ? [SEP] the city is too busy and loud\n","\n","Subjects:   {'the city', 'SPEAKER1'}\n","Predicates: {'want', 'been', 'is'}\n","Objects:    {'too busy', 'new york city', 'live in new york city', 'loud'}\n","\n","[CLS] SPEAKER1 both like the outdoor s then  ! SPEAKER1 like working out at the park too  . [SEP] do SPEAKER1 like the outdoor s  ? [SEP] yes\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'like'}\n","Objects:    {'working', 'the park', 'the outdoors'}\n","\n","[CLS] SPEAKER1  ' m an electronics technician  . [SEP] do SPEAKER1 fix computers  ? [SEP] in some ways SPEAKER1 can depending how extensive the damage is  .\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'fix', 'can'}\n","Objects:    {'how extensive', 'the damage is', 'an electronics technician', 'computers'}\n","\n","[CLS] SPEAKER1 like ice d coffee with flavor s in it  . [SEP] are SPEAKER1 craving any specific flavor s  ? [SEP] at the moment  , SPEAKER1  ' m mad for so y sauce  .\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'like', 'craving', 'mad'}\n","Objects:    {'specific flavors', 'soy sauce', 'iced coffee with flavors in it'}\n","\n","[CLS] SPEAKER1 deliver people s items from the post office to their homes  . [SEP] do SPEAKER1 remember the old lady that lived by the post office  ? [SEP] yes\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'deliver', 'lived', 'remember'}\n","Objects:    {'their homes', 'the old lady that lived', 'the post office', 'peoples items from the post office'}\n","\n","[CLS] that seems fun  , SPEAKER1 walk 5 days a week  , 2 3 hours [SEP] cool  , maybe SPEAKER2 can come sometime  ? [SEP] SPEAKER2 can  !  ! it would be fun  !  !\n","\n","Subjects:   {'SPEAKER1', 'that', 'SPEAKER2', 'it'}\n","Predicates: {'can', 'seems', 'would', 'walk', 'be'}\n","Objects:    {'2 3 hours', 'sometime', 'fun', '5 days a week'}\n","\n","[CLS] SPEAKER1 do not have friends because they think SPEAKER1  ' m too smart [SEP] do SPEAKER1 see any of SPEAKER2  ' s old friends  ? [SEP] SPEAKER1 see a couple of them\n","\n","Subjects:   {'SPEAKER1'}\n","Predicates: {'have', 'see'}\n","Objects:    {'a couple of them', 'too smart', 'friends', \"ofSPEAKER2 's old friends\"}\n","\n","[CLS] if SPEAKER2 do  n ' t mind  , SPEAKER1  ' d rather SPEAKER2 did  n ' t  . SPEAKER1 have a cold and feel chilly  . [SEP] oh  , that  ' s too bad  . should SPEAKER2 call a doctor  ? [SEP] SPEAKER1  ' d appreciate it if SPEAKER2 would  .\n","\n","Subjects:   {'SPEAKER1', 'that', 'SPEAKER2'}\n","Predicates: {'appreciate', 'mind', 'rather', 'should', 'feel', 'have'}\n","Objects:    {'too bad', 'a cold', 'a doctor', 'it', 'chilly'}\n","\n","[CLS] it  ' s about 200 years old  . it has a lot of history  ! [SEP] sounds fascinating  . where is SPEAKER1  ' s new house located  ? [SEP] it  ' s just off of the ring road  .\n","\n","Subjects:   {'it', \"SPEAKER1 's new house\"}\n","Predicates: {'located', 'has', 'is', 'sounds'}\n","Objects:    {'fascinating', 'the ring road', 'about 200 years old', 'a lot of history'}\n","\n","[CLS] SPEAKER1 am doing okay  . trying to figure out how to take a bath  . [SEP] have SPEAKER1 tried filling the tub  ? [SEP] SPEAKER1  ' ve a water all er gy  , small amounts are all SPEAKER1 can do  .\n","\n","Subjects:   {'SPEAKER1', 'small'}\n","Predicates: {'doing', 'are', 'tried', 'trying'}\n","Objects:    {'filling the tub', 'figure out how to take a bath', 'SPEAKER1 can do', 'all', 'small amounts', 'a water allergy', 'okay'}\n","\n","[CLS] SPEAKER1 think SPEAKER2  ' ve got the flu  . there  ' s a lot of it about  . [SEP] what should SPEAKER2 do  ? [SEP] take some medicine and stay in bed for a day or two  .\n","\n","Subjects:   {'there', 'SPEAKER2'}\n","Predicates: {'stay', 'should', 'take', 'got'}\n","Objects:    {'a day or two', 'a lot of it about', 'some medicine', 'the flu'}\n","\n","[CLS] sure  , SPEAKER1  ' ll sit right here  . [SEP] wonderful  , does anyone have any questions about this project  ? [SEP] SPEAKER1 am confused about the projected revenues  .\n","\n","Subjects:   {'anyone', 'SPEAKER1'}\n","Predicates: {'confused', 'have', 'sit', 'am'}\n","Objects:    {'the projected revenues', 'this project', 'questions'}\n","\n","[CLS] yes  , it is  . this perfume just arrived yesterday  , and it  ' s the latest products of chan el  . [SEP] really  ? how much is it  ? [SEP] 55 dollars  , madam  .\n","\n","Subjects:   {'this perfume', 'it'}\n","Predicates: {'arrived', 'is'}\n","Objects:    {'55 dollars', 'the latest products of chanel'}\n","\n","[CLS] hi  , dave  . this is zi na  . [SEP] zi na  ? zi na the snake  ? [SEP] SPEAKER1 got SPEAKER2  ' s email a couple of months back  .\n","\n","Subjects:   {'this', 'SPEAKER1'}\n","Predicates: {'is', 'got'}\n","Objects:    {'the snake', 'zina', \"SPEAKER2 's email\"}\n","\n","[CLS] it  ' s fish steamed and served with SPEAKER1  ' s special sauce  . [SEP] is it good  ? [SEP] sure  . it  ' s a most popular dish  .\n","\n","Subjects:   {'it'}\n","Predicates: {'served', 'is'}\n","Objects:    {'good', 'fish steamed', 'a most popular dish', \"SPEAKER1 's special sauce\"}\n","\n","[CLS] oh  , no  . rocky is a pilot  . [SEP] really  ? where does he fly  ? does he fly to other countries  ? [SEP] yes  . mostly to england and france  .\n","\n","Subjects:   {'he', 'rocky'}\n","Predicates: {'mostly', 'fly', 'is'}\n","Objects:    {'other countries', 'england', 'france', 'a pilot'}\n","\n","[CLS] it seems that SPEAKER2 will have a nice day tomorrow  . [SEP] how about SPEAKER1  ? what are SPEAKER1 going to do tomorrow  ? [SEP] SPEAKER1 have a lot of work in the office and a lot of chor es in the house  . how SPEAKER1 envy SPEAKER2  , robin  !\n","\n","Subjects:   {'SPEAKER1', 'SPEAKER2'}\n","Predicates: {'will', 'are', 'envy', 'going', 'have'}\n","Objects:    {'the office', 'a lot of work', 'SPEAKER2', 'robin', 'a nice day', 'a lot of chores in the house'}\n","\n"]}],"source":["for input in disambig_inputs:\n","  y_subj, y_pred, y_obj, subwords = argex_model.predict(input)\n","\n","  print(' '.join(subwords).replace('▁', '') + '\\n')\n","  print('Subjects:  ', bio_tags_to_tokens(subwords, y_subj.T, one_hot=True))\n","  print('Predicates:', bio_tags_to_tokens(subwords, y_pred.T, predicate=True, one_hot=True))\n","  print('Objects:   ', bio_tags_to_tokens(subwords, y_obj.T, one_hot=True))\n","  print()"]},{"cell_type":"markdown","source":["Save model"],"metadata":{"id":"D9lKPFppTKMS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGzYhb7S9STW","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1670593016430,"user_tz":-60,"elapsed":325,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"e9787238-c6a4-4ae7-d6c5-d4aabd7631d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/Communicative Robotics/models/baseline2022-12-09/argument_extraction_albert-base-v2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["import os, shutil\n","\n","# out_dir = root_dir + '/models/' + str(date.today())\n","out_dir = root_dir + '/models/' + 'baseline' + str(date.today())\n","if not os.path.exists(out_dir):\n","    os.mkdir(out_dir)\n","\n","shutil.copy('argument_extraction_albert-base-v2', out_dir)\n"]},{"cell_type":"code","source":["y_subj, y_pred, y_obj, subwords = argex_model.predict(['Good', 'morning', '.', '<eos>', \"What's\", 'the', 'problem', '?', '<eos>', \"SPEAKER2\", \"'m\", 'running', 'a', 'high', 'fever', 'and', 'feeling', 'terribly', 'bad', '.'])\n","\n","print(y_subj, y_pred, y_obj)"],"metadata":{"id":"lRkaBpa10rZq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"huUDGyQEJiLe"},"source":["# Ranking the triples\n","\n","Now we are able to extract the candidate arguments, but how do we combine them?\n","\n","We compute all combinations of the subjects, predicates and objects and train a model to distinguish between those triples that are entailed (not considering negation here) and those that are not.\n","\n","For this, we extract a number of negative examples from possible triples, i.e. those combinations of subjects, predicates and objects that were not annotated."]},{"cell_type":"markdown","metadata":{"id":"D_GyAqbPKvFE"},"source":["## Converting format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQDaXHQTJkb9"},"outputs":[],"source":["from collections import defaultdict\n","from copy import deepcopy\n","\n","\n","def extract_triples(annotation, neg_oversampling=7, contr_oversampling=0.7, ellipsis_oversampling=3):\n","    \"\"\" Extracts plain-text triples from an annotation file and samples 'negative' examples by\n","        crossover. By default, the function will over-extract triples with negative polarity and\n","        elliptical constructions to counter class imbalance.\n","\n","        params:\n","        dict annotation:            loaded annotation file (see load_annotations)\n","        int neg_oversampling:       how much to over-sample triples with negative polarity\n","        float contr_oversampling:   how much to sample contrast/invalid triples relative to true triples\n","        int ellipsis_oversampling:  how much to over-sample elliptical triples\n","    \"\"\"\n","    turns = annotation['tokens']\n","    triple_ids = [t[:4] for t in annotation['annotations']]\n","\n","    arguments = defaultdict(list)\n","    triples = []\n","    labels = []\n","\n","    # Oversampling of elliptical triples\n","    for triple in deepcopy(triple_ids):\n","        subj_obj_turns = set([i for i, _ in triple[0] + triple[2]])\n","        if len(subj_obj_turns) > 1:\n","            triple_ids += [triple] * int(ellipsis_oversampling)\n","\n","    # Extract 'True' triples\n","    for subj, pred, obj, polar in triple_ids:\n","\n","        subj = ' '.join(turns[i][j] for i, j in subj) if subj else ''\n","        pred = ' '.join(turns[i][j] for i, j in pred) if pred else ''\n","        obj = ' '.join(turns[i][j] for i, j in obj) if obj else ''\n","\n","        if subj or pred or obj:\n","\n","            if not polar:\n","                triples += [(subj, pred, obj)]\n","                labels += [1]\n","            else:\n","                triples += [(subj, pred, obj)] * neg_oversampling  # Oversampling negative polarities\n","                labels += [2] * neg_oversampling\n","\n","            arguments['subjs'].append(subj)\n","            arguments['preds'].append(pred)\n","            arguments['objs'].append(obj)\n","\n","    # Skip if the annotation file was blank\n","    if not triples:\n","        return [], [], []\n","\n","    # Sample fake contrast examples (invalid extractions)\n","    n = int(len(triples) * contr_oversampling)\n","    for i in range(50):\n","        s = random.choice(arguments['subjs'])\n","        p = random.choice(arguments['preds'])\n","        o = random.choice(arguments['objs'])\n","\n","        # Ensure samples are new (and not actually valid!)\n","        if (s, p, o) not in triples and s and p and o:\n","            triples += [(s, p, o)]\n","            labels += [0]\n","            n -= 1\n","\n","        # Create as many fake examples as there were 'real' triples\n","        if n == 0:\n","            break\n","\n","    return turns, triples, labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PelPIZlwKVpY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670864612213,"user_tz":-60,"elapsed":500,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"71b3e8d0-ddc4-4694-8fb6-1325dde040f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokens:  ['did', 'SPEAKER2', 'vote', 'for', 'him', '?', '<eos>', 'SPEAKER2', 'sure', 'did', '.', 'how', 'about', 'SPEAKER1', '?', '<eos>', 'SPEAKER1', 'voted', 'for', 'him', '.', '<eos>']\n","triples: [('SPEAKER2', 'vote for', 'him'), ('SPEAKER1', 'voted for', 'him'), ('SPEAKER1', 'vote for', 'him')]\n","labels:  [1, 1, 0]\n"]}],"source":["tokens, triples, labels = [], [], []\n","for ann in annotations:\n","    ann_tokens, ann_triples, triple_labels = extract_triples(ann)\n","    triples.append(ann_triples)\n","    labels.append(triple_labels)\n","    tokens.append([t for ts in ann_tokens for t in ts + ['<eos>']])\n","\n","j = random.choice(range(len(tokens)))\n","print('tokens: ', tokens[j])\n","print('triples:', triples[j])\n","print('labels: ', labels[j])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyTk8d2m9VZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670864615086,"user_tz":-60,"elapsed":335,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"056286db-044d-4823-b4cc-e865e0afdb7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class (im)balance:\n","not entailed   6431\n","entailed (pos) 6690\n","entailed (neg) 5978\n"]}],"source":["print('Class (im)balance:')\n","print('not entailed  ', sum([np.sum(np.array(t) == 0) for t in labels]))\n","print('entailed (pos)', sum([np.sum(np.array(t) == 1) for t in labels]))\n","print('entailed (neg)', sum([np.sum(np.array(t) == 2) for t in labels]))"]},{"cell_type":"markdown","metadata":{"id":"KSg00eFtKyyK"},"source":["## Fine-tuning ALBERT for Triple Candidate Scoring"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECqJdf96KyX_"},"outputs":[],"source":["class TripleScoring(torch.nn.Module):\n","    def __init__(self, base_model='albert-base-v2', path=None, max_len=80, sep='<eos>'):\n","        super().__init__()\n","        # Base model\n","        print('loading %s for triple scoring' % base_model)\n","        # Load base model\n","        self._model = AutoModel.from_pretrained(base_model)\n","        self._max_len = max_len\n","        self._base = base_model\n","        self._sep = sep\n","\n","        # Load and extend tokenizer with SPEAKERS\n","        self._tokenizer = AutoTokenizer.from_pretrained(base_model)\n","        self._tokenizer.add_tokens(['SPEAKER1', 'SPEAKER2'], special_tokens=True)\n","        self._model.resize_token_embeddings(len(self._tokenizer))\n","\n","        # SPO candidate scoring head\n","        hidden_size = AutoConfig.from_pretrained(base_model).hidden_size\n","        self._head = torch.nn.Linear(hidden_size, 3)\n","        self._relu = torch.nn.ReLU()\n","        self._softmax = torch.nn.Softmax(dim=-1)\n","\n","        # GPU support\n","        self._device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","        self.to(self._device)\n","\n","        # Load model / tokenizer if pretrained model is given\n","        if path:\n","            print('\\t- Loading pretrained')\n","            model_path = glob.glob(path + '/candidate_scorer_' + base_model)[0]\n","            self.load_state_dict(torch.load(model_path, map_location=self._device))\n","\n","    def forward(self, input_ids, speaker_ids, attn_mask):\n","        \"\"\" Computes the forward pass through the model\n","        \"\"\"\n","        out = self._model(input_ids=input_ids, token_type_ids=speaker_ids, attention_mask=attn_mask)\n","        h = self._relu(out.last_hidden_state[:, 0])\n","        return self._softmax(self._head(h))\n","\n","    def _retokenize_dialogue(self, tokens, speaker=1):\n","        # Tokenize each token individually (keeping track of subwords)\n","        f_input_ids = [self._tokenizer.cls_token_id]\n","        speaker_ids = [speaker]\n","        for turn in ' '.join(tokens).split(self._sep):\n","            token_ids = self._tokenizer.encode(turn, add_special_tokens=True)[1:]  # strip [CLS]\n","            f_input_ids += token_ids\n","            speaker_ids += [speaker] * len(token_ids)\n","            speaker = 1 - speaker\n","\n","        return f_input_ids, speaker_ids\n","\n","    def _retokenize_triple(self, triple):\n","        # Append triple\n","        f_input_ids = self._tokenizer.encode(' '.join(triple), add_special_tokens=False)\n","        speaker_ids = [0] * len(f_input_ids)\n","        return f_input_ids, speaker_ids\n","\n","    def _add_padding(self, sequence, pad_token):\n","        # If sequence is too long, cut off end\n","        sequence = sequence[:self._max_len]\n","\n","        # Pad remainder to max_len\n","        padding = self._max_len - len(sequence)\n","        new_sequence = sequence + [pad_token] * padding\n","\n","        # Mask out [PAD] tokens\n","        attn_mask = [1] * len(sequence) + [0] * padding\n","        return new_sequence, attn_mask\n","\n","    def fit(self, tokens, triples, labels, epochs=2, lr=1e-6):\n","        \"\"\" Fits the model to the annotations\n","        \"\"\"\n","        X = []\n","        for tokens, triple_lst, triple_labels in zip(tokens, triples, labels):\n","\n","            # Tokenize dialogue\n","            dialog_input_ids, dialog_speakers = self._retokenize_dialogue(tokens)\n","\n","            for triple, label in zip(triple_lst, triple_labels):\n","                # Tokenize triple\n","                triple_input_ids, triple_speakers = self._retokenize_triple(triple)\n","\n","                # Concatenate dialogue + [UNK] + triple\n","                input_ids = dialog_input_ids[:-1] + [self._tokenizer.unk_token_id] + triple_input_ids\n","                speakers = dialog_speakers[:-1] + [0] + triple_speakers\n","\n","                # Pad sequence with [PAD] to max_len\n","                input_ids, _ = self._add_padding(input_ids, self._tokenizer.pad_token_id)\n","                speakers, attn_mask = self._add_padding(speakers, 0)\n","\n","                # Push Tensor to GPU\n","                input_ids = torch.LongTensor([input_ids]).to(self._device)\n","                speakers = torch.LongTensor([speakers]).to(self._device)\n","                attn_mask = torch.FloatTensor([attn_mask]).to(self._device)\n","                label_ids = torch.LongTensor([label]).to(self._device)\n","\n","                X.append((input_ids, speakers, attn_mask, label_ids))\n","\n","        # Set up optimizer and objective\n","        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","        criterion = torch.nn.CrossEntropyLoss()\n","\n","        for epoch in range(epochs):\n","            random.shuffle(X)\n","\n","            losses = []\n","            for input_ids, speaker_ids, attn_mask, y in tqdm(X):\n","                # Was the triple entailed? Positively? Negatively?\n","                y_hat = self(input_ids, speaker_ids, attn_mask)\n","                loss = criterion(y_hat, y)\n","                losses.append(loss.item())\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","            print(\"mean loss =\", np.mean(losses))\n","\n","        # Save model to file\n","        torch.save(self.state_dict(), 'candidate_scorer_%s' % self._base)\n","\n","    def predict(self, tokens, triples):\n","        # Tokenize dialogue\n","        dialog_input_ids, dialog_speakers = self._retokenize_dialogue(tokens)\n","\n","        batch_input_ids = []\n","        batch_speakers = []\n","        batch_attn_mask = []\n","\n","        for triple in triples:\n","            # Tokenize triple\n","            triple_input_ids, triple_speakers = self._retokenize_triple(triple)\n","\n","            # Concatenate dialogue + [UNK] + triple\n","            input_ids = dialog_input_ids + [self._tokenizer.unk_token_id] + triple_input_ids\n","            speakers = dialog_speakers + [0] + triple_speakers\n","\n","            # Pad sequence with [PAD] to max_len\n","            input_ids, _ = self._add_padding(input_ids, self._tokenizer.pad_token_id)\n","            speakers, attn_mask = self._add_padding(speakers, 0)\n","\n","            batch_input_ids.append(input_ids)\n","            batch_speakers.append(speakers)\n","            batch_attn_mask.append(attn_mask)\n","\n","        # Push batches to GPU\n","        batch_input_ids = torch.LongTensor(batch_input_ids).to(self._device)\n","        batch_speakers = torch.LongTensor(batch_speakers).to(self._device)\n","        batch_attn_mask = torch.FloatTensor(batch_attn_mask).to(self._device)\n","\n","        label = self(batch_input_ids, batch_speakers, batch_attn_mask)\n","        label = label.cpu().detach().numpy()\n","        return label"]},{"cell_type":"code","source":["#load pretrained model\n","#triplescorer_model = TripleScoring(path=root_dir+'/models/baseline2022-12-09')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeFzXnNZSXp0","executionInfo":{"status":"ok","timestamp":1670864627778,"user_tz":-60,"elapsed":3488,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"a24960ed-5e96-4217-d5cc-8d1dfc561214"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading albert-base-v2 for triple scoring\n","\t- Loading pretrained\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XKejimSO56J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670598165158,"user_tz":-60,"elapsed":4942561,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"16c1180d-0c66-4279-bbd0-15c1a5f27000"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading albert-base-v2 for triple scoring\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [12:31<00:00, 25.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.8256498628235502\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [11:46<00:00, 27.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.6630780672386243\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [11:37<00:00, 27.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.6284048839612711\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [11:28<00:00, 27.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.611301173039365\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [11:33<00:00, 27.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.6033324699320163\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [11:42<00:00, 27.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.5961232537333148\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 19087/19087 [11:34<00:00, 27.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["mean loss = 0.5922655518242205\n"]}],"source":["# scorer = TripleScoring()\n","# scorer.fit(tokens, triples, labels, epochs=7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38y3V1onaRNn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670864656551,"user_tz":-60,"elapsed":414,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"e39c7898-a101-4b11-ab55-483ce989209b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.998, 0.   , 0.001],\n","       [0.003, 0.945, 0.052],\n","       [0.003, 0.952, 0.045],\n","       [0.001, 0.001, 0.998],\n","       [0.   , 0.   , 1.   ],\n","       [0.   , 0.   , 1.   ],\n","       [0.999, 0.   , 0.001],\n","       [0.   , 0.   , 1.   ],\n","       [0.362, 0.009, 0.629]], dtype=float32)"]},"metadata":{},"execution_count":27}],"source":["# inputs = 'staying here is fine though . SPEAKER1\\'s two dogs keep me company <eos> SPEAKER2 do not love them ! What car do SPEAKER1 drive ? <eos> a toyota . but SPEAKER1 like nissans . <eos>'.split()\n","# triple_examples = [['SPEAKER1', 'drive', 'nissans'],\n","#                    ['SPEAKER1', 'like', 'nissans'], \n","#                    ['SPEAKER2', 'like', 'nissans'], \n","#                    ['SPEAKER2', 'love', 'two dogs'], \n","#                    ['SPEAKER1', 'drive', 'a toyota']]\n","\n","# inputs = '<eos> Do SPEAKER1 work in Amsterdam ? <eos> No , in London . <eos>'.split()\n","# triple_examples = [['SPEAKER1', 'work in', 'Amsterdam']]\n","\n","inputs = 'SPEAKER1 adore unicorns but not photography <eos> What do SPEAKER1 like ? <eos> dogs and gaming, but not cats or elephants . <eos>'.split()\n","triple_examples = [['SPEAKER1', 'adore', 'cats'], \n","                   ['SPEAKER1', 'like', 'dogs'],\n","                   ['SPEAKER1', 'like', 'gaming'],\n","                   ['SPEAKER1', 'adore', 'photography'],\n","                   ['SPEAKER1', 'like', 'cats'],\n","                   ['SPEAKER1', 'like', 'elephants'],\n","                   ['SPEAKER1', 'adore', 'elephants'],\n","                   ['SPEAKER1', 'like', 'photography'],\n","                   ['SPEAKER1', 'like', 'unicorns']]\n","\n","np.round(triplescorer_model.predict(inputs, triple_examples), 3)"]},{"cell_type":"markdown","metadata":{"id":"4fO8VBMJMwKJ"},"source":["We move the resulting model to Drive:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OienwgD4_8Ml","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1670598553029,"user_tz":-60,"elapsed":323,"user":{"displayName":"Dorien Renting","userId":"02236066021659360815"}},"outputId":"fdfe45dd-bdc0-4c73-e9a7-472b151bba7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/Communicative Robotics/models/baseline2022-12-09/candidate_scorer_albert-base-v2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}],"source":["import os, shutil\n","\n","out_dir = root_dir + '/models/baseline' + str(date.today())\n","if not os.path.exists(out_dir):\n","    os.mkdir(out_dir)\n","\n","shutil.copy('candidate_scorer_albert-base-v2', out_dir)"]},{"cell_type":"code","source":[],"metadata":{"id":"3iEpcP8GbudV"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1JMLbCzzdtQYYrOHQg-j38ulakEXWeUHN","timestamp":1664271069285},{"file_id":"1JdIEIFqyf6bn2hPRfV4diEE1X4YLfeh0","timestamp":1646750393565}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"db9506adfd6049ef944efee21df2a9df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70c27d97c0e8405fa37bae0bd85295a9","IPY_MODEL_93fabb0e7fc84bd2abbe8169a56fdd8c","IPY_MODEL_77a5ab39232048899e83826fe94d9340"],"layout":"IPY_MODEL_29b49cd55ca44a91b1c52d170f1e688a"}},"70c27d97c0e8405fa37bae0bd85295a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc5f44b3b8994a8283a1e0ef51e7bedb","placeholder":"​","style":"IPY_MODEL_75541f6a7456470eb40d2f44d8f81dcd","value":"Downloading: 100%"}},"93fabb0e7fc84bd2abbe8169a56fdd8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d06ed96d7954b68b5f51955ab0a5e78","max":684,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5973d4e85b8c4677ba86c614b7e82f5a","value":684}},"77a5ab39232048899e83826fe94d9340":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fba6ab1e8b14dcf91a47a47aa3268f2","placeholder":"​","style":"IPY_MODEL_4c093a96fc1a480580038924c00399e6","value":" 684/684 [00:00&lt;00:00, 15.9kB/s]"}},"29b49cd55ca44a91b1c52d170f1e688a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc5f44b3b8994a8283a1e0ef51e7bedb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75541f6a7456470eb40d2f44d8f81dcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d06ed96d7954b68b5f51955ab0a5e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5973d4e85b8c4677ba86c614b7e82f5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7fba6ab1e8b14dcf91a47a47aa3268f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c093a96fc1a480580038924c00399e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"872243ded5a6448e82636a58336ff065":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6f0d2664d294768bf364013f3dcd9ed","IPY_MODEL_4a2aaa3154fe4503a7e6956790e1953c","IPY_MODEL_c32812ae022d4e48aef8fbf372062230"],"layout":"IPY_MODEL_3c013369960c46aebf85526075594686"}},"d6f0d2664d294768bf364013f3dcd9ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f375de562b9f4f6e9f4c71b0e1c72c4b","placeholder":"​","style":"IPY_MODEL_275df89cb1be4682bdca87d2ee427bfc","value":"Downloading: 100%"}},"4a2aaa3154fe4503a7e6956790e1953c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69cec72d603f42eab551aeea510a829a","max":47376696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_baa99d837c3b4b76a500198d42a45316","value":47376696}},"c32812ae022d4e48aef8fbf372062230":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_411b500460da4ee2873368851c375016","placeholder":"​","style":"IPY_MODEL_1fb8160b9ec747568077595f4e0dbb9b","value":" 47.4M/47.4M [00:00&lt;00:00, 75.6MB/s]"}},"3c013369960c46aebf85526075594686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f375de562b9f4f6e9f4c71b0e1c72c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"275df89cb1be4682bdca87d2ee427bfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69cec72d603f42eab551aeea510a829a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa99d837c3b4b76a500198d42a45316":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"411b500460da4ee2873368851c375016":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb8160b9ec747568077595f4e0dbb9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28488812e2194f5d8b1d223225da4c44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1aac2da00424f668f6143072f6cbb40","IPY_MODEL_dd87c1eb131f444882ed26be2c0560ea","IPY_MODEL_7a71c5e007e84172ad7f48999311d4e1"],"layout":"IPY_MODEL_7d736a276c1848328e2528b8c6666f21"}},"c1aac2da00424f668f6143072f6cbb40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92edb21e1dbf412a81fcd715cef7aed7","placeholder":"​","style":"IPY_MODEL_d3dac2ba3e844a1c8113500f6d4b173a","value":"Downloading: 100%"}},"dd87c1eb131f444882ed26be2c0560ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc2c51bac2944000b01542ce45c12273","max":760289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf10223bf5e5465db18f96b65a506d65","value":760289}},"7a71c5e007e84172ad7f48999311d4e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_927038389972430389bab43e6782767e","placeholder":"​","style":"IPY_MODEL_6423e83cbf68426294e8363b205ec655","value":" 760k/760k [00:00&lt;00:00, 869kB/s]"}},"7d736a276c1848328e2528b8c6666f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92edb21e1dbf412a81fcd715cef7aed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3dac2ba3e844a1c8113500f6d4b173a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc2c51bac2944000b01542ce45c12273":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf10223bf5e5465db18f96b65a506d65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"927038389972430389bab43e6782767e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6423e83cbf68426294e8363b205ec655":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a4ef63326e7446a92e6d08b287713bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a94907d95684179882d443375ea4e21","IPY_MODEL_5ce288934bee4126bc527731d12bffa6","IPY_MODEL_42c66435b0f144caaa5404d0225b78ed"],"layout":"IPY_MODEL_0a2931959a2b450793d3a5e60b3f93d3"}},"9a94907d95684179882d443375ea4e21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bd0ea686e384d99ba08d8585113f30b","placeholder":"​","style":"IPY_MODEL_7c120bf86e29457e8fc5bafd334d2fc4","value":"Downloading: 100%"}},"5ce288934bee4126bc527731d12bffa6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08d4757bfbb74f0a8b552fcfabb574d4","max":1312669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d79b6f122880498e8ec80d9a740d613b","value":1312669}},"42c66435b0f144caaa5404d0225b78ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a908e1f12174a2399a333188399979d","placeholder":"​","style":"IPY_MODEL_970c57dc8e944a3abe89e695b483e383","value":" 1.31M/1.31M [00:00&lt;00:00, 2.26MB/s]"}},"0a2931959a2b450793d3a5e60b3f93d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd0ea686e384d99ba08d8585113f30b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c120bf86e29457e8fc5bafd334d2fc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08d4757bfbb74f0a8b552fcfabb574d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79b6f122880498e8ec80d9a740d613b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a908e1f12174a2399a333188399979d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"970c57dc8e944a3abe89e695b483e383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}